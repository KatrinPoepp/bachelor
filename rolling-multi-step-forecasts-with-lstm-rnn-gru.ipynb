{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037823,
     "end_time": "2021-07-29T02:53:21.559836",
     "exception": false,
     "start_time": "2021-07-29T02:53:21.522013",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Time-series forecasting: Rolling multi-step forecasts with Recurrent Neural Networks\n",
    "Recurrent Neural Networks (RNN, LSTM, GRU) are capable of learning long-term dependencies from the input sequence, support additional exogeneous features as input. Looking at the results below, they are really good at time-series forecasting out of the box with minimal feature engineering! However, RNNs are also rather tricky to work with since they take in a 3D input, which may be hard for beginners to work with. Hopefully this notebook serves as sufficient code for you to adapt in your own work, but any queries I will try my best to answer here, or via [GitHub](https://github.com/mingboiz)\n",
    "\n",
    "\n",
    "![img](https://github.com/mingboi95/forecasting/blob/main/img/Summary.jpg?raw=true)\n",
    "\n",
    "\n",
    "For the sake of simplicity, a very simple train-test split is used, with data down-sampled to daily frequency for ease of interpretation. \n",
    "This notebook serves as a guide for forecasting time-series with Deep Learning methods, and it implements the following time-series forecasting with:\n",
    "- Multiple features (multivariate time-series forecasting)\n",
    "- Multi-step and multiple features forecasting (multivariate, multi-step time-series forecasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036665,
     "end_time": "2021-07-29T02:53:21.633266",
     "exception": false,
     "start_time": "2021-07-29T02:53:21.596601",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037403,
     "end_time": "2021-07-29T02:53:21.707431",
     "exception": false,
     "start_time": "2021-07-29T02:53:21.670028",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The helper evaluation functions are available [here](https://www.kaggle.com/mingboi/rnn-utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:53:21.787065Z",
     "iopub.status.busy": "2021-07-29T02:53:21.786426Z",
     "iopub.status.idle": "2021-07-29T02:53:29.113946Z",
     "shell.execute_reply": "2021-07-29T02:53:29.113406Z",
     "shell.execute_reply.started": "2021-07-20T04:49:17.631124Z"
    },
    "papermill": {
     "duration": 7.368879,
     "end_time": "2021-07-29T02:53:29.114043",
     "exception": false,
     "start_time": "2021-07-29T02:53:21.745164",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from rnn_utils import mae, mse, rmse, mape, evaluate # helper evaluation functions\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:53:29.166194Z",
     "iopub.status.busy": "2021-07-29T02:53:29.165690Z",
     "iopub.status.idle": "2021-07-29T02:53:44.345039Z",
     "shell.execute_reply": "2021-07-29T02:53:44.344325Z",
     "shell.execute_reply.started": "2021-07-20T04:49:17.646431Z"
    },
    "papermill": {
     "duration": 15.206317,
     "end_time": "2021-07-29T02:53:44.345159",
     "exception": false,
     "start_time": "2021-07-29T02:53:29.138842",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                   ds  Global_active_power  Global_reactive_power  Voltage  \\\n0 2006-12-16 17:24:00                4.216                  0.418   234.84   \n1 2006-12-16 17:25:00                5.360                  0.436   233.63   \n2 2006-12-16 17:26:00                5.374                  0.498   233.29   \n3 2006-12-16 17:27:00                5.388                  0.502   233.74   \n4 2006-12-16 17:28:00                3.666                  0.528   235.68   \n\n   Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n0              18.4             0.0             1.0            17.0  \n1              23.0             0.0             1.0            16.0  \n2              23.0             0.0             2.0            17.0  \n3              23.0             0.0             1.0            17.0  \n4              15.8             0.0             1.0            17.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ds</th>\n      <th>Global_active_power</th>\n      <th>Global_reactive_power</th>\n      <th>Voltage</th>\n      <th>Global_intensity</th>\n      <th>Sub_metering_1</th>\n      <th>Sub_metering_2</th>\n      <th>Sub_metering_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2006-12-16 17:24:00</td>\n      <td>4.216</td>\n      <td>0.418</td>\n      <td>234.84</td>\n      <td>18.4</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2006-12-16 17:25:00</td>\n      <td>5.360</td>\n      <td>0.436</td>\n      <td>233.63</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2006-12-16 17:26:00</td>\n      <td>5.374</td>\n      <td>0.498</td>\n      <td>233.29</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2006-12-16 17:27:00</td>\n      <td>5.388</td>\n      <td>0.502</td>\n      <td>233.74</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2006-12-16 17:28:00</td>\n      <td>3.666</td>\n      <td>0.528</td>\n      <td>235.68</td>\n      <td>15.8</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>17.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_PATH = \"./files/household_power_consumption.txt\"\n",
    "df = pd.read_csv(FILE_PATH, sep=\";\", parse_dates={'ds':['Date', 'Time']}, na_values=['nan', '?'], infer_datetime_format=True,low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02534,
     "end_time": "2021-07-29T02:53:44.396173",
     "exception": false,
     "start_time": "2021-07-29T02:53:44.370833",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Attribute Information\n",
    "\n",
    "1. ds: Date in format dd/mm/yyyy\n",
    "2. time: time in format hh:mm:ss\n",
    "3. globalactivepower: household global minute-averaged active power (in kilowatt)\n",
    "4. globalreactivepower: household global minute-averaged reactive power (in kilowatt)\n",
    "5. voltage: minute-averaged voltage (in volt)\n",
    "6. global_intensity: household global minute-averaged current intensity (in ampere)\n",
    "7. submetering1: energy sub-metering No. 1 (in watt-hour of active energy). It corresponds to the kitchen, containing mainly a dishwasher, an oven and a microwave (hot plates are not electric but gas powered).\n",
    "8. submetering2: energy sub-metering No. 2 (in watt-hour of active energy). It corresponds to the laundry room, containing a washing-machine, a tumble-drier, a refrigerator and a light.\n",
    "9. submetering3: energy sub-metering No. 3 (in watt-hour of active energy). It corresponds to an electric water-heater and an air-conditioner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:53:44.448618Z",
     "iopub.status.busy": "2021-07-29T02:53:44.448085Z",
     "iopub.status.idle": "2021-07-29T02:53:44.616260Z",
     "shell.execute_reply": "2021-07-29T02:53:44.616765Z",
     "shell.execute_reply.started": "2021-07-20T04:49:33.384686Z"
    },
    "papermill": {
     "duration": 0.19553,
     "end_time": "2021-07-29T02:53:44.616935",
     "exception": false,
     "start_time": "2021-07-29T02:53:44.421405",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\poeppelmann\\AppData\\Local\\Temp\\ipykernel_23644\\1161634671.py:4: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.iloc[:,j]=df.iloc[:,j].fillna(df.iloc[:,j].mean())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missing values: {df.isnull().sum().any()}\")\n",
    "# imputation with the columns means\n",
    "for j in range(0,8):        \n",
    "  df.iloc[:,j]=df.iloc[:,j].fillna(df.iloc[:,j].mean())\n",
    "# checking for missing values\n",
    "print(f\"Missing values: {df.isnull().sum().any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024667,
     "end_time": "2021-07-29T02:53:44.667473",
     "exception": false,
     "start_time": "2021-07-29T02:53:44.642806",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To simplify the problem, we just wish to forecast the future household electricity consumption, we will do some pre-processing to frame this problem properly:\n",
    "- Downsampling from minute-average activate power to daily active power for households\n",
    "- Imputation missing values with column mean\n",
    "- MinMax Normalization to preserve variable distributions for our Recurrent Neural Networks\n",
    "\n",
    "The dataset is now daily France household electricity data from `2006-12-23` until `2010-11-26`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:53:44.720674Z",
     "iopub.status.busy": "2021-07-29T02:53:44.719970Z",
     "iopub.status.idle": "2021-07-29T02:53:44.906858Z",
     "shell.execute_reply": "2021-07-29T02:53:44.906360Z",
     "shell.execute_reply.started": "2021-07-20T04:49:33.667113Z"
    },
    "papermill": {
     "duration": 0.214534,
     "end_time": "2021-07-29T02:53:44.906951",
     "exception": false,
     "start_time": "2021-07-29T02:53:44.692417",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                   y\nds                  \n2006-12-16  1209.176\n2006-12-17  3390.460\n2006-12-18  2203.826\n2006-12-19  1666.194\n2006-12-20  2225.748",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y</th>\n    </tr>\n    <tr>\n      <th>ds</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2006-12-16</th>\n      <td>1209.176</td>\n    </tr>\n    <tr>\n      <th>2006-12-17</th>\n      <td>3390.460</td>\n    </tr>\n    <tr>\n      <th>2006-12-18</th>\n      <td>2203.826</td>\n    </tr>\n    <tr>\n      <th>2006-12-19</th>\n      <td>1666.194</td>\n    </tr>\n    <tr>\n      <th>2006-12-20</th>\n      <td>2225.748</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resample = df.resample('D', on='ds').sum() \n",
    "df_resample.rename(columns={\"Global_active_power\":\"y\"}, inplace=True)\n",
    "df_resample = df_resample[['y']]\n",
    "df_resample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024933,
     "end_time": "2021-07-29T02:53:44.957065",
     "exception": false,
     "start_time": "2021-07-29T02:53:44.932132",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024996,
     "end_time": "2021-07-29T02:53:45.007278",
     "exception": false,
     "start_time": "2021-07-29T02:53:44.982282",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we have some helper functions that help to create some simple lagged features to add into our model. You incorporate more complicated time-series features in your own work.\n",
    "\n",
    "Recurrent Neural Networks can take in additional features as a 3-D array for input, where the three dimensions of this input are `sample`, `time_steps` and `features`:\n",
    "\n",
    "1. Samples - One sequence is one sample. A batch is comprised of one or more samples.\n",
    "2. Time Steps - One time step is one point of observation in the sample.\n",
    "3. Features - One feature is one observation at a time step.\n",
    "\n",
    "This means that the input layer expects a 3D array of data when fitting the model and when making predictions, even if specific dimensions of the array contain a single value, e.g. one sample or one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:53:45.068375Z",
     "iopub.status.busy": "2021-07-29T02:53:45.067845Z",
     "iopub.status.idle": "2021-07-29T02:53:45.071301Z",
     "shell.execute_reply": "2021-07-29T02:53:45.070754Z",
     "shell.execute_reply.started": "2021-07-20T04:49:33.76747Z"
    },
    "papermill": {
     "duration": 0.038754,
     "end_time": "2021-07-29T02:53:45.071408",
     "exception": false,
     "start_time": "2021-07-29T02:53:45.032654",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_lags(df, days=7):\n",
    "    # create lagged data for features\n",
    "    for i in range(days):\n",
    "        df[\"Lag_{lag}\".format(lag=i+1)] = df['y'].shift(i+1)\n",
    "    return df\n",
    "\n",
    "def create_features(X, time_steps=1, n_features=7):\n",
    "    # create 3d dataset for input\n",
    "    cols, names = list(), list()\n",
    "    for i in range(1, time_steps+1):\n",
    "        cols.append(X.shift(-time_steps))\n",
    "        names += [name + \"_\" + str(i) for name in X.columns]\n",
    "        agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    agg = agg.values.reshape(agg.shape[0], time_steps, n_features)\n",
    "    return agg\n",
    "\n",
    "def create_dataset(df, yhat):\n",
    "    # yhat needs to be scaled\n",
    "    preds = pd.DataFrame(yhat.flatten())\n",
    "    temp = pd.concat([df.iloc[:,0], preds])\n",
    "    temp.columns = ['y']\n",
    "    date_idx = pd.date_range(start='2006-12-23', periods=temp.shape[0])\n",
    "    temp.set_index(date_idx, inplace=True)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025125,
     "end_time": "2021-07-29T02:53:45.122410",
     "exception": false,
     "start_time": "2021-07-29T02:53:45.097285",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We preprocess by normalizing all variables first, taking care to avoid data leakage by using our MinMaxScaler on training data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:53:45.182186Z",
     "iopub.status.busy": "2021-07-29T02:53:45.181662Z",
     "iopub.status.idle": "2021-07-29T02:53:45.237820Z",
     "shell.execute_reply": "2021-07-29T02:53:45.237171Z",
     "shell.execute_reply.started": "2021-07-20T04:49:33.786275Z"
    },
    "papermill": {
     "duration": 0.089583,
     "end_time": "2021-07-29T02:53:45.237931",
     "exception": false,
     "start_time": "2021-07-29T02:53:45.148348",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\poeppelmann\\.conda\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 7 features, but MinMaxScaler is expecting 1 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m scaler_x \u001B[38;5;241m=\u001B[39m scaler\u001B[38;5;241m.\u001B[39mfit(chosen\u001B[38;5;241m.\u001B[39miloc[:\u001B[38;5;241m1096\u001B[39m,\u001B[38;5;241m1\u001B[39m:])\n\u001B[0;32m      8\u001B[0m scaler_y \u001B[38;5;241m=\u001B[39m scaler\u001B[38;5;241m.\u001B[39mfit(chosen\u001B[38;5;241m.\u001B[39miloc[:\u001B[38;5;241m1096\u001B[39m,\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m---> 10\u001B[0m x_scaled \u001B[38;5;241m=\u001B[39m \u001B[43mscaler_x\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchosen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m y_scaled \u001B[38;5;241m=\u001B[39m scaler_y\u001B[38;5;241m.\u001B[39mtransform(chosen\u001B[38;5;241m.\u001B[39mloc[:,[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m]])\n\u001B[0;32m     13\u001B[0m scaled \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mhstack((x_scaled, y_scaled))\n",
      "File \u001B[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 140\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    142\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    143\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m    144\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    145\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    146\u001B[0m         )\n",
      "File \u001B[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:508\u001B[0m, in \u001B[0;36mMinMaxScaler.transform\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    494\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Scale features of X according to feature_range.\u001B[39;00m\n\u001B[0;32m    495\u001B[0m \n\u001B[0;32m    496\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    504\u001B[0m \u001B[38;5;124;03m    Transformed data.\u001B[39;00m\n\u001B[0;32m    505\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    506\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 508\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    509\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    511\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mFLOAT_DTYPES\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    512\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    513\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    514\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    516\u001B[0m X \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale_\n\u001B[0;32m    517\u001B[0m X \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_\n",
      "File \u001B[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:588\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    585\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    587\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 588\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_n_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    590\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\sklearn\\base.py:389\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[1;34m(self, X, reset)\u001B[0m\n\u001B[0;32m    386\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[1;32m--> 389\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    390\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    391\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    392\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: X has 7 features, but MinMaxScaler is expecting 1 features as input."
     ]
    }
   ],
   "source": [
    "chosen = df_resample.copy()\n",
    "chosen = create_lags(chosen)\n",
    "chosen.dropna(inplace=True)\n",
    "\n",
    "# Fit scaler on training data only to prevent data leakage\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_x = scaler.fit(chosen.iloc[:1096,1:])\n",
    "scaler_y = scaler.fit(chosen.iloc[:1096,0].values.reshape(-1,1))\n",
    "\n",
    "x_scaled = scaler_x.transform(chosen.iloc[:,1:])\n",
    "y_scaled = scaler_y.transform(chosen.loc[:,['y']])\n",
    "\n",
    "scaled = np.hstack((x_scaled, y_scaled))\n",
    "scaled = pd.DataFrame(scaled, index=chosen.index, columns=chosen.columns)\n",
    "print(scaled.shape)\n",
    "scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025816,
     "end_time": "2021-07-29T02:53:45.290067",
     "exception": false,
     "start_time": "2021-07-29T02:53:45.264251",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train-val-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025964,
     "end_time": "2021-07-29T02:53:45.342223",
     "exception": false,
     "start_time": "2021-07-29T02:53:45.316259",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We a simple train-test split for illustration purposes, where we predict for values from `2010-06-01` onwards for the test set.\n",
    "\n",
    "Train - `2006-12-23` - `2009-12-22`  \n",
    "Val - `2009-12-23` - `2010-05-31`  \n",
    "Test - `2010-06-01` - `2010-11-26`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:53:45.403742Z",
     "iopub.status.busy": "2021-07-29T02:53:45.403232Z",
     "iopub.status.idle": "2021-07-29T02:53:45.405403Z",
     "shell.execute_reply": "2021-07-29T02:53:45.404985Z",
     "shell.execute_reply.started": "2021-07-20T04:49:33.834679Z"
    },
    "papermill": {
     "duration": 0.037031,
     "end_time": "2021-07-29T02:53:45.405493",
     "exception": false,
     "start_time": "2021-07-29T02:53:45.368462",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = scaled[:1096]\n",
    "val = scaled[1096:1256]\n",
    "test = scaled[1256:]\n",
    "x_train = train.drop([\"y\"],axis=1)\n",
    "y_train = train[\"y\"]\n",
    "x_val = val.drop([\"y\"],axis=1)\n",
    "y_val = val[\"y\"]\n",
    "x_test = test.drop([\"y\"],axis=1)\n",
    "y_test = test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:53:45.474382Z",
     "iopub.status.busy": "2021-07-29T02:53:45.465366Z",
     "iopub.status.idle": "2021-07-29T02:53:45.485319Z",
     "shell.execute_reply": "2021-07-29T02:53:45.484766Z",
     "shell.execute_reply.started": "2021-07-20T04:49:33.84779Z"
    },
    "papermill": {
     "duration": 0.053198,
     "end_time": "2021-07-29T02:53:45.485423",
     "exception": false,
     "start_time": "2021-07-29T02:53:45.432225",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train_np = create_features(x_train, 7, 7)\n",
    "x_val_np = create_features(x_val, 7, 7)\n",
    "x_test_np = create_features(x_test, 7, 7)\n",
    "#print(x_train_np.shape, x_val_np.shape, x_test_np.shape)\n",
    "y_test = y_test[:x_test_np.shape[0]]\n",
    "y_train = y_train[:x_train_np.shape[0]]\n",
    "y_val = y_val[:x_val_np.shape[0]]\n",
    "#print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025927,
     "end_time": "2021-07-29T02:53:45.537803",
     "exception": false,
     "start_time": "2021-07-29T02:53:45.511876",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Forecasting with Recurrent Neural Networks\n",
    "Here's a helper function to help us train our RNNs, LSTMs, GRUs, where we then forecast with them to get the normalized predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:53:45.597086Z",
     "iopub.status.busy": "2021-07-29T02:53:45.596519Z",
     "iopub.status.idle": "2021-07-29T02:53:45.600192Z",
     "shell.execute_reply": "2021-07-29T02:53:45.599650Z",
     "shell.execute_reply.started": "2021-07-20T04:49:33.888245Z"
    },
    "papermill": {
     "duration": 0.036728,
     "end_time": "2021-07-29T02:53:45.600288",
     "exception": false,
     "start_time": "2021-07-29T02:53:45.563560",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fit_model(m, units, x_train_np, x_val_np, verbose=False):\n",
    "    model = Sequential()\n",
    "    model.add(m (units = units, return_sequences = True, input_shape = [x_train_np.shape[1], x_train_np.shape[2]]))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(m (units = units))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 1))\n",
    "    # Compile Model\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # Fit Model\n",
    "    history = model.fit(x_train_np, y_train, epochs=50, batch_size=70, \n",
    "                        validation_data=(x_val_np, y_val), verbose=False, shuffle=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:53:45.659954Z",
     "iopub.status.busy": "2021-07-29T02:53:45.659440Z",
     "iopub.status.idle": "2021-07-29T02:54:19.646741Z",
     "shell.execute_reply": "2021-07-29T02:54:19.646324Z",
     "shell.execute_reply.started": "2021-07-20T04:49:33.90103Z"
    },
    "papermill": {
     "duration": 34.018289,
     "end_time": "2021-07-29T02:54:19.646840",
     "exception": false,
     "start_time": "2021-07-29T02:53:45.628551",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RNN_model = fit_model(SimpleRNN, 64, x_train_np, x_val_np)\n",
    "LSTM_model = fit_model(LSTM, 64, x_train_np, x_val_np)\n",
    "GRU_model = fit_model(GRU, 64, x_train_np, x_val_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:54:19.701609Z",
     "iopub.status.busy": "2021-07-29T02:54:19.700910Z",
     "iopub.status.idle": "2021-07-29T02:54:21.162122Z",
     "shell.execute_reply": "2021-07-29T02:54:21.161643Z",
     "shell.execute_reply.started": "2021-07-20T04:50:09.261045Z"
    },
    "papermill": {
     "duration": 1.48918,
     "end_time": "2021-07-29T02:54:21.162218",
     "exception": false,
     "start_time": "2021-07-29T02:54:19.673038",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RNN_preds = RNN_model.predict(x_test_np)\n",
    "LSTM_preds = LSTM_model.predict(x_test_np)\n",
    "GRU_preds = GRU_model.predict(x_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0255,
     "end_time": "2021-07-29T02:54:21.213822",
     "exception": false,
     "start_time": "2021-07-29T02:54:21.188322",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.1 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:54:21.270340Z",
     "iopub.status.busy": "2021-07-29T02:54:21.269751Z",
     "iopub.status.idle": "2021-07-29T02:54:21.274243Z",
     "shell.execute_reply": "2021-07-29T02:54:21.273680Z",
     "shell.execute_reply.started": "2021-07-20T04:50:10.911344Z"
    },
    "papermill": {
     "duration": 0.034727,
     "end_time": "2021-07-29T02:54:21.274338",
     "exception": false,
     "start_time": "2021-07-29T02:54:21.239611",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resultsDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:54:21.335646Z",
     "iopub.status.busy": "2021-07-29T02:54:21.335145Z",
     "iopub.status.idle": "2021-07-29T02:54:21.340698Z",
     "shell.execute_reply": "2021-07-29T02:54:21.341075Z",
     "shell.execute_reply.started": "2021-07-20T04:50:10.91805Z"
    },
    "papermill": {
     "duration": 0.040702,
     "end_time": "2021-07-29T02:54:21.341224",
     "exception": false,
     "start_time": "2021-07-29T02:54:21.300522",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rnn_preds = scaler_y.inverse_transform(RNN_preds)\n",
    "y_test_actual = scaler_y.inverse_transform(pd.DataFrame(y_test))\n",
    "resultsDict['RNN'] = evaluate(y_test_actual, rnn_preds)\n",
    "evaluate(y_test_actual, rnn_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:54:21.400378Z",
     "iopub.status.busy": "2021-07-29T02:54:21.399758Z",
     "iopub.status.idle": "2021-07-29T02:54:21.929045Z",
     "shell.execute_reply": "2021-07-29T02:54:21.928469Z",
     "shell.execute_reply.started": "2021-07-20T04:50:10.938054Z"
    },
    "papermill": {
     "duration": 0.561236,
     "end_time": "2021-07-29T02:54:21.929161",
     "exception": false,
     "start_time": "2021-07-29T02:54:21.367925",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(rnn_preds, \"r-\", label=\"Predicted\")\n",
    "plt.plot(y_test_actual, label=\"Actual\")\n",
    "plt.title('RNN')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('1 - RNN.jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028331,
     "end_time": "2021-07-29T02:54:21.986186",
     "exception": false,
     "start_time": "2021-07-29T02:54:21.957855",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:54:22.051673Z",
     "iopub.status.busy": "2021-07-29T02:54:22.051087Z",
     "iopub.status.idle": "2021-07-29T02:54:22.055652Z",
     "shell.execute_reply": "2021-07-29T02:54:22.054354Z",
     "shell.execute_reply.started": "2021-07-20T04:50:11.598606Z"
    },
    "papermill": {
     "duration": 0.041281,
     "end_time": "2021-07-29T02:54:22.055754",
     "exception": false,
     "start_time": "2021-07-29T02:54:22.014473",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lstm_preds = scaler_y.inverse_transform(LSTM_preds)\n",
    "y_test_actual = scaler_y.inverse_transform(pd.DataFrame(y_test))\n",
    "resultsDict['LSTM'] = evaluate(y_test_actual, lstm_preds)\n",
    "evaluate(y_test_actual, lstm_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:54:22.127688Z",
     "iopub.status.busy": "2021-07-29T02:54:22.127012Z",
     "iopub.status.idle": "2021-07-29T02:54:22.501148Z",
     "shell.execute_reply": "2021-07-29T02:54:22.500642Z",
     "shell.execute_reply.started": "2021-07-20T04:50:11.614845Z"
    },
    "papermill": {
     "duration": 0.416658,
     "end_time": "2021-07-29T02:54:22.501237",
     "exception": false,
     "start_time": "2021-07-29T02:54:22.084579",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(lstm_preds, \"r-\", label=\"Predicted\")\n",
    "plt.plot(y_test_actual, label=\"Actual\")\n",
    "plt.title('LSTM')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('2 - LSTM.jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029701,
     "end_time": "2021-07-29T02:54:22.561018",
     "exception": false,
     "start_time": "2021-07-29T02:54:22.531317",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.3 GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:54:22.630144Z",
     "iopub.status.busy": "2021-07-29T02:54:22.629621Z",
     "iopub.status.idle": "2021-07-29T02:54:22.632627Z",
     "shell.execute_reply": "2021-07-29T02:54:22.632248Z",
     "shell.execute_reply.started": "2021-07-20T04:50:12.16771Z"
    },
    "papermill": {
     "duration": 0.04165,
     "end_time": "2021-07-29T02:54:22.632721",
     "exception": false,
     "start_time": "2021-07-29T02:54:22.591071",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gru_preds = scaler_y.inverse_transform(GRU_preds)\n",
    "y_test_actual = scaler_y.inverse_transform(pd.DataFrame(y_test))\n",
    "resultsDict['GRU'] = evaluate(y_test_actual, gru_preds)\n",
    "evaluate(y_test_actual, gru_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:54:22.703710Z",
     "iopub.status.busy": "2021-07-29T02:54:22.700053Z",
     "iopub.status.idle": "2021-07-29T02:54:23.083407Z",
     "shell.execute_reply": "2021-07-29T02:54:23.082882Z",
     "shell.execute_reply.started": "2021-07-20T04:50:12.181869Z"
    },
    "papermill": {
     "duration": 0.420089,
     "end_time": "2021-07-29T02:54:23.083499",
     "exception": false,
     "start_time": "2021-07-29T02:54:22.663410",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(gru_preds, \"r-\", label=\"Predicted\")\n",
    "plt.plot(y_test_actual, label=\"Actual\")\n",
    "plt.title('GRU')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('3 - GRU.jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032729,
     "end_time": "2021-07-29T02:54:23.149303",
     "exception": false,
     "start_time": "2021-07-29T02:54:23.116574",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. Rolling Forecast with RNN, LSTM, GRU\n",
    "Instead of forecasting out a very long sequence out `2010-06-01` to `2010-11-23`, 175 days between them is a medium-length sequence. Anecdotally, I can handle up to 300-length sequences with LSTM and GRU, but should experiment with a rolling forecasting schemes to see if it handles the potential vanishing gradient problem. \n",
    "\n",
    "By rolling, we mean that we train on initial train set, predict next month. Expand training window to include the predictions from next month, then repeat the following cycle until we have our desired 175 prediction window:\n",
    "1. Predict one month ahead\n",
    "2. Create features based on predictions\n",
    "3. Expand training window to include the predictions\n",
    "\n",
    "This means that the maximum output sequence is 30-length long and can be readily handled without vanishing gradient problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:54:23.225436Z",
     "iopub.status.busy": "2021-07-29T02:54:23.223603Z",
     "iopub.status.idle": "2021-07-29T02:54:23.243054Z",
     "shell.execute_reply": "2021-07-29T02:54:23.243491Z",
     "shell.execute_reply.started": "2021-07-20T04:50:12.724895Z"
    },
    "papermill": {
     "duration": 0.061125,
     "end_time": "2021-07-29T02:54:23.243610",
     "exception": false,
     "start_time": "2021-07-29T02:54:23.182485",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chosen = df_resample.copy()\n",
    "chosen = create_lags(chosen)\n",
    "chosen.dropna(inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_x = scaler.fit(chosen.iloc[:1096,1:])\n",
    "scaler_y = scaler.fit(chosen.iloc[:1096,0].values.reshape(-1,1))\n",
    "\n",
    "x_scaled = scaler_x.transform(chosen.iloc[:,1:])\n",
    "y_scaled = scaler_y.transform(chosen.loc[:,['y']])\n",
    "\n",
    "scaled = np.hstack((x_scaled, y_scaled))\n",
    "scaled = pd.DataFrame(scaled, index=chosen.index, columns=chosen.columns)\n",
    "\n",
    "train = scaled[:1078]\n",
    "val = scaled[1078:1256]\n",
    "test = scaled[1256:]\n",
    "\n",
    "x_train = train.drop([\"y\"],axis=1)\n",
    "y_train = train[\"y\"]\n",
    "x_val = val.drop([\"y\"],axis=1)\n",
    "y_val = val[\"y\"]\n",
    "x_test = test.drop([\"y\"],axis=1)\n",
    "y_test = test[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032804,
     "end_time": "2021-07-29T02:54:23.309547",
     "exception": false,
     "start_time": "2021-07-29T02:54:23.276743",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Recreate the dataset, and write some helper functions for preprocessing, forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:54:23.386056Z",
     "iopub.status.busy": "2021-07-29T02:54:23.383518Z",
     "iopub.status.idle": "2021-07-29T02:54:23.404267Z",
     "shell.execute_reply": "2021-07-29T02:54:23.403835Z",
     "shell.execute_reply.started": "2021-07-20T04:50:12.76218Z"
    },
    "papermill": {
     "duration": 0.06201,
     "end_time": "2021-07-29T02:54:23.404375",
     "exception": false,
     "start_time": "2021-07-29T02:54:23.342365",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Helper Function\n",
    "i = 0\n",
    "def train_test_split(df, i=0):\n",
    "    chosen = create_lags(df)\n",
    "    chosen.dropna(inplace=True)\n",
    "    x_scaled = scaler_x.transform(chosen.iloc[:,1:])\n",
    "    y_scaled = scaler_y.transform(chosen.loc[:,['y']])\n",
    "\n",
    "    scaled = np.hstack((x_scaled, y_scaled))\n",
    "    scaled = pd.DataFrame(scaled, index=chosen.index, columns=chosen.columns)\n",
    "\n",
    "    train = scaled[:1078+i]\n",
    "    val = scaled[1078+i:1256+i]\n",
    "    test = scaled[1256+i:]\n",
    "    \n",
    "    x_train = train.drop([\"y\"],axis=1)\n",
    "    y_train = train[\"y\"]\n",
    "    x_val = val.drop([\"y\"],axis=1)\n",
    "    y_val = val[\"y\"]\n",
    "    x_test = test.drop([\"y\"],axis=1)\n",
    "    y_test = test[\"y\"]\n",
    "\n",
    "    n_features = len(x_train.columns)\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = train_test_split(df_resample, i)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032915,
     "end_time": "2021-07-29T02:54:23.470765",
     "exception": false,
     "start_time": "2021-07-29T02:54:23.437850",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use a simple for loop here of train, predict, re-train, predict our forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:54:23.552431Z",
     "iopub.status.busy": "2021-07-29T02:54:23.551652Z",
     "iopub.status.idle": "2021-07-29T02:58:03.108020Z",
     "shell.execute_reply": "2021-07-29T02:58:03.108461Z",
     "shell.execute_reply.started": "2021-07-20T04:50:12.797382Z"
    },
    "papermill": {
     "duration": 219.6043,
     "end_time": "2021-07-29T02:58:03.108585",
     "exception": false,
     "start_time": "2021-07-29T02:54:23.504285",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TIME_STEPS, N_FEATURES = 7, 7\n",
    "rnn, lstm, gru = list(), list(), list()\n",
    "\n",
    "for i in range(0, len(x_test), 30):\n",
    "    temp = df_resample.copy()\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test = train_test_split(temp, i)\n",
    "    \n",
    "    x_train_np = create_features(x_train, TIME_STEPS, N_FEATURES)\n",
    "    x_val_np = create_features(x_val, TIME_STEPS, N_FEATURES)\n",
    "    x_test_np = create_features(x_test, TIME_STEPS, N_FEATURES)\n",
    "    #print(x_train_np.shape, x_val_np.shape, x_test_np.shape)\n",
    "    y_test = y_test[:x_test_np.shape[0]]\n",
    "    y_train = y_train[:x_train_np.shape[0]]\n",
    "    y_val = y_val[:x_val_np.shape[0]]\n",
    "    #print(y_train.shape, y_val.shape, y_test.shape)\n",
    "    \n",
    "    if y_test.shape[0] != 0:\n",
    "        RNN_model = fit_model(SimpleRNN, 64, x_train_np, x_val_np)\n",
    "        LSTM_model = fit_model(LSTM, 64, x_train_np, x_val_np)\n",
    "        GRU_model = fit_model(GRU, 64, x_train_np, x_val_np)\n",
    "\n",
    "        RNN_preds = RNN_model.predict(x_test_np)\n",
    "        yhat_actual = scaler_y.inverse_transform(RNN_preds)\n",
    "        rnn.extend(yhat_actual.flatten()[:30])\n",
    "        LSTM_preds = LSTM_model.predict(x_test_np)\n",
    "        yhat_actual = scaler_y.inverse_transform(LSTM_preds)\n",
    "        lstm.extend(yhat_actual.flatten()[:30])\n",
    "        GRU_preds = GRU_model.predict(x_test_np)\n",
    "        yhat_actual = scaler_y.inverse_transform(GRU_preds)\n",
    "        gru.extend(yhat_actual.flatten()[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032418,
     "end_time": "2021-07-29T02:58:03.174255",
     "exception": false,
     "start_time": "2021-07-29T02:58:03.141837",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Because we are using the first 7 inputs as sequence to create features, then dropping the NA values, we have to first do:\n",
    "```\n",
    "y_test_actual[7:]\n",
    "```\n",
    "to enforce the lengths of the test values and the predictions to be of equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:58:03.244712Z",
     "iopub.status.busy": "2021-07-29T02:58:03.244206Z",
     "iopub.status.idle": "2021-07-29T02:58:03.250805Z",
     "shell.execute_reply": "2021-07-29T02:58:03.250314Z",
     "shell.execute_reply.started": "2021-07-20T04:54:07.725472Z"
    },
    "papermill": {
     "duration": 0.043765,
     "end_time": "2021-07-29T02:58:03.250912",
     "exception": false,
     "start_time": "2021-07-29T02:58:03.207147",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resultsDict['RNN Rolling'] = evaluate(y_test_actual[7:], rnn)\n",
    "evaluate(y_test_actual[7:], rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:58:03.335485Z",
     "iopub.status.busy": "2021-07-29T02:58:03.328158Z",
     "iopub.status.idle": "2021-07-29T02:58:03.713503Z",
     "shell.execute_reply": "2021-07-29T02:58:03.713034Z",
     "shell.execute_reply.started": "2021-07-20T04:54:07.7403Z"
    },
    "papermill": {
     "duration": 0.429107,
     "end_time": "2021-07-29T02:58:03.713602",
     "exception": false,
     "start_time": "2021-07-29T02:58:03.284495",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(rnn, \"r-\", label=\"Predicted\")\n",
    "plt.plot(y_test_actual[7:], label=\"Actual\")\n",
    "plt.legend()\n",
    "plt.title('Rolling RNN')\n",
    "plt.grid(True)\n",
    "plt.savefig('4 - RNN (Rolling).jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:58:03.786526Z",
     "iopub.status.busy": "2021-07-29T02:58:03.785856Z",
     "iopub.status.idle": "2021-07-29T02:58:03.791346Z",
     "shell.execute_reply": "2021-07-29T02:58:03.791987Z",
     "shell.execute_reply.started": "2021-07-20T04:54:08.347106Z"
    },
    "papermill": {
     "duration": 0.043562,
     "end_time": "2021-07-29T02:58:03.792155",
     "exception": false,
     "start_time": "2021-07-29T02:58:03.748593",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resultsDict['LSTM Rolling'] = evaluate(y_test_actual[7:], lstm)\n",
    "evaluate(y_test_actual[7:], lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:58:03.896885Z",
     "iopub.status.busy": "2021-07-29T02:58:03.896187Z",
     "iopub.status.idle": "2021-07-29T02:58:04.283578Z",
     "shell.execute_reply": "2021-07-29T02:58:04.284131Z",
     "shell.execute_reply.started": "2021-07-20T04:54:08.36039Z"
    },
    "papermill": {
     "duration": 0.441619,
     "end_time": "2021-07-29T02:58:04.284294",
     "exception": false,
     "start_time": "2021-07-29T02:58:03.842675",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(lstm, \"r-\", label=\"Predicted\")\n",
    "plt.plot(y_test_actual[7:], label=\"Actual\")\n",
    "plt.legend()\n",
    "plt.title('Rolling LSTM')\n",
    "plt.grid(True)\n",
    "plt.savefig('5 - LSTM (Rolling).jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:58:04.393926Z",
     "iopub.status.busy": "2021-07-29T02:58:04.393198Z",
     "iopub.status.idle": "2021-07-29T02:58:04.400684Z",
     "shell.execute_reply": "2021-07-29T02:58:04.401075Z",
     "shell.execute_reply.started": "2021-07-20T04:54:08.910064Z"
    },
    "papermill": {
     "duration": 0.064065,
     "end_time": "2021-07-29T02:58:04.401227",
     "exception": false,
     "start_time": "2021-07-29T02:58:04.337162",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resultsDict['GRU Rolling'] = evaluate(y_test_actual[7:], gru)\n",
    "evaluate(y_test_actual[7:], gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:58:04.481651Z",
     "iopub.status.busy": "2021-07-29T02:58:04.480721Z",
     "iopub.status.idle": "2021-07-29T02:58:04.864918Z",
     "shell.execute_reply": "2021-07-29T02:58:04.864491Z",
     "shell.execute_reply.started": "2021-07-20T04:54:08.921701Z"
    },
    "papermill": {
     "duration": 0.424811,
     "end_time": "2021-07-29T02:58:04.865021",
     "exception": false,
     "start_time": "2021-07-29T02:58:04.440210",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(gru, \"r-\", label=\"Predicted\")\n",
    "plt.plot(y_test_actual[7:], label=\"Actual\")\n",
    "plt.legend()\n",
    "plt.title('Rolling GRU')\n",
    "plt.grid(True)\n",
    "plt.savefig('6 - GRU (Rolling).jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04021,
     "end_time": "2021-07-29T02:58:04.945518",
     "exception": false,
     "start_time": "2021-07-29T02:58:04.905308",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:58:05.032646Z",
     "iopub.status.busy": "2021-07-29T02:58:05.032019Z",
     "iopub.status.idle": "2021-07-29T02:58:05.034949Z",
     "shell.execute_reply": "2021-07-29T02:58:05.035331Z",
     "shell.execute_reply.started": "2021-07-20T04:54:10.149509Z"
    },
    "papermill": {
     "duration": 0.049199,
     "end_time": "2021-07-29T02:58:05.035452",
     "exception": false,
     "start_time": "2021-07-29T02:58:04.986253",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resultsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T02:58:05.130265Z",
     "iopub.status.busy": "2021-07-29T02:58:05.124918Z",
     "iopub.status.idle": "2021-07-29T02:58:06.716468Z",
     "shell.execute_reply": "2021-07-29T02:58:06.716872Z",
     "shell.execute_reply.started": "2021-07-20T04:54:10.158379Z"
    },
    "papermill": {
     "duration": 1.640919,
     "end_time": "2021-07-29T02:58:06.716999",
     "exception": false,
     "start_time": "2021-07-29T02:58:05.076080",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig,a =  plt.subplots(3,2, figsize=(25,9))\n",
    "\n",
    "a[0][0].plot(rnn_preds, \"r-\", label=\"Predicted\")\n",
    "a[0][0].plot(y_test_actual, label=\"Actual\")\n",
    "a[0][0].legend()\n",
    "a[0][0].grid(True)\n",
    "a[0][0].set_title('RNN')\n",
    "a[0][1].plot(rnn, \"r-\", label=\"Predicted\")\n",
    "a[0][1].plot(y_test_actual[7:], label=\"Actual\")\n",
    "a[0][1].legend()\n",
    "a[0][1].grid(True)\n",
    "a[0][1].set_title('Rolling RNN')\n",
    "a[1][0].plot(lstm_preds, \"r-\", label=\"Predicted\")\n",
    "a[1][0].plot(y_test_actual, label=\"Actual\")\n",
    "a[1][0].legend()\n",
    "a[1][0].grid(True)\n",
    "a[1][0].set_title('LSTM')\n",
    "a[1][1].plot(lstm, \"r-\", label=\"Predicted\")\n",
    "a[1][1].plot(y_test_actual[7:], label=\"Actual\")\n",
    "a[1][1].legend()\n",
    "a[1][1].grid(True)\n",
    "a[1][1].set_title('Rolling LSTM')\n",
    "a[2][0].plot(gru_preds, \"r-\", label=\"Predicted\")\n",
    "a[2][0].plot(y_test_actual, label=\"Actual\")\n",
    "a[2][0].legend()\n",
    "a[2][0].grid(True)\n",
    "a[2][0].set_title('GRU')\n",
    "a[2][1].plot(gru, \"r-\", label=\"Predicted\")\n",
    "a[2][1].plot(y_test_actual[7:], label=\"Actual\")\n",
    "a[2][1].legend()\n",
    "a[2][1].grid(True)\n",
    "a[2][1].set_title('Rolling GRU')\n",
    "plt.savefig('Summary.jpg', dpi=200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 291.108828,
   "end_time": "2021-07-29T02:58:07.786671",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-29T02:53:16.677843",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}