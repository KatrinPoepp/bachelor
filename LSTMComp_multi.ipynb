{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt  # Visualization\n",
    "import warnings  # Supress warnings\n",
    "import os\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\poeppelmann\\AppData\\Local\\Temp\\ipykernel_3028\\2003050442.py:18: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Seed value\n",
    "SEED = 2023\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "random.seed(SEED)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "            Rainfall  Depth_to_Groundwater  Temperature  Drainage_Volume  \\\nDate                                                                       \n2009-01-01       0.0              0.175907     0.242507         0.672018   \n2009-01-02       0.0              0.177960     0.163488         0.507291   \n2009-01-03       0.0              0.180698     0.220708         0.624189   \n2009-01-04       0.0              0.182067     0.122616         0.540839   \n2009-01-05       0.0              0.184805     0.049046         0.465917   \n...              ...                   ...          ...              ...   \n2020-06-26       0.0              0.591376     0.801090         0.462974   \n2020-06-27       0.0              0.588638     0.814714         0.408690   \n2020-06-28       0.0              0.583162     0.833787         0.378186   \n2020-06-29       0.0              0.583847     0.833787         0.436952   \n2020-06-30       0.0              0.579055     0.844687         0.387584   \n\n            River_Hydrometry  year  month  day  day_of_year  week_of_year  \\\nDate                                                                        \n2009-01-01          0.260870  2009      1    1            1             1   \n2009-01-02          0.304348  2009      1    2            2             1   \n2009-01-03          0.260870  2009      1    3            3             1   \n2009-01-04          0.260870  2009      1    4            4             1   \n2009-01-05          0.217391  2009      1    5            5             2   \n...                      ...   ...    ...  ...          ...           ...   \n2020-06-26          0.304348  2020      6   26          178            26   \n2020-06-27          0.260870  2020      6   27          179            26   \n2020-06-28          0.260870  2020      6   28          180            26   \n2020-06-29          0.260870  2020      6   29          181            27   \n2020-06-30          0.260870  2020      6   30          182            27   \n\n            ...       day_sin   day_cos  day_of_year_sin  day_of_year_cos  \\\nDate        ...                                                             \n2009-01-01  ...  2.079117e-01  0.978148         0.017213         0.999852   \n2009-01-02  ...  4.067366e-01  0.913545         0.034422         0.999407   \n2009-01-03  ...  5.877853e-01  0.809017         0.051620         0.998667   \n2009-01-04  ...  7.431448e-01  0.669131         0.068802         0.997630   \n2009-01-05  ...  8.660254e-01  0.500000         0.085965         0.996298   \n...         ...           ...       ...              ...              ...   \n2020-06-26  ... -7.431448e-01  0.669131         0.077386        -0.997001   \n2020-06-27  ... -5.877853e-01  0.809017         0.060213        -0.998186   \n2020-06-28  ... -4.067366e-01  0.913545         0.043022        -0.999074   \n2020-06-29  ... -2.079117e-01  0.978148         0.025818        -0.999667   \n2020-06-30  ... -1.133108e-15  1.000000         0.008607        -0.999963   \n\n            week_of_year_sin  week_of_year_cos   quarter_sin   quarter_cos  \\\nDate                                                                         \n2009-01-01          0.120208          0.992749  1.000000e+00  6.123234e-17   \n2009-01-02          0.120208          0.992749  1.000000e+00  6.123234e-17   \n2009-01-03          0.120208          0.992749  1.000000e+00  6.123234e-17   \n2009-01-04          0.120208          0.992749  1.000000e+00  6.123234e-17   \n2009-01-05          0.238673          0.971100  1.000000e+00  6.123234e-17   \n...                      ...               ...           ...           ...   \n2020-06-26          0.008610         -0.999963  1.224647e-16 -1.000000e+00   \n2020-06-27          0.008610         -0.999963  1.224647e-16 -1.000000e+00   \n2020-06-28          0.008610         -0.999963  1.224647e-16 -1.000000e+00   \n2020-06-29         -0.111656         -0.993747  1.224647e-16 -1.000000e+00   \n2020-06-30         -0.111656         -0.993747  1.224647e-16 -1.000000e+00   \n\n            season_sin    season_cos  \nDate                                  \n2009-01-01         1.0  6.123234e-17  \n2009-01-02         1.0  6.123234e-17  \n2009-01-03         1.0  6.123234e-17  \n2009-01-04         1.0  6.123234e-17  \n2009-01-05         1.0  6.123234e-17  \n...                ...           ...  \n2020-06-26        -1.0 -1.836970e-16  \n2020-06-27        -1.0 -1.836970e-16  \n2020-06-28        -1.0 -1.836970e-16  \n2020-06-29        -1.0 -1.836970e-16  \n2020-06-30        -1.0 -1.836970e-16  \n\n[4199 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rainfall</th>\n      <th>Depth_to_Groundwater</th>\n      <th>Temperature</th>\n      <th>Drainage_Volume</th>\n      <th>River_Hydrometry</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>day_of_year</th>\n      <th>week_of_year</th>\n      <th>...</th>\n      <th>day_sin</th>\n      <th>day_cos</th>\n      <th>day_of_year_sin</th>\n      <th>day_of_year_cos</th>\n      <th>week_of_year_sin</th>\n      <th>week_of_year_cos</th>\n      <th>quarter_sin</th>\n      <th>quarter_cos</th>\n      <th>season_sin</th>\n      <th>season_cos</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2009-01-01</th>\n      <td>0.0</td>\n      <td>0.175907</td>\n      <td>0.242507</td>\n      <td>0.672018</td>\n      <td>0.260870</td>\n      <td>2009</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2.079117e-01</td>\n      <td>0.978148</td>\n      <td>0.017213</td>\n      <td>0.999852</td>\n      <td>0.120208</td>\n      <td>0.992749</td>\n      <td>1.000000e+00</td>\n      <td>6.123234e-17</td>\n      <td>1.0</td>\n      <td>6.123234e-17</td>\n    </tr>\n    <tr>\n      <th>2009-01-02</th>\n      <td>0.0</td>\n      <td>0.177960</td>\n      <td>0.163488</td>\n      <td>0.507291</td>\n      <td>0.304348</td>\n      <td>2009</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>4.067366e-01</td>\n      <td>0.913545</td>\n      <td>0.034422</td>\n      <td>0.999407</td>\n      <td>0.120208</td>\n      <td>0.992749</td>\n      <td>1.000000e+00</td>\n      <td>6.123234e-17</td>\n      <td>1.0</td>\n      <td>6.123234e-17</td>\n    </tr>\n    <tr>\n      <th>2009-01-03</th>\n      <td>0.0</td>\n      <td>0.180698</td>\n      <td>0.220708</td>\n      <td>0.624189</td>\n      <td>0.260870</td>\n      <td>2009</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>5.877853e-01</td>\n      <td>0.809017</td>\n      <td>0.051620</td>\n      <td>0.998667</td>\n      <td>0.120208</td>\n      <td>0.992749</td>\n      <td>1.000000e+00</td>\n      <td>6.123234e-17</td>\n      <td>1.0</td>\n      <td>6.123234e-17</td>\n    </tr>\n    <tr>\n      <th>2009-01-04</th>\n      <td>0.0</td>\n      <td>0.182067</td>\n      <td>0.122616</td>\n      <td>0.540839</td>\n      <td>0.260870</td>\n      <td>2009</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>...</td>\n      <td>7.431448e-01</td>\n      <td>0.669131</td>\n      <td>0.068802</td>\n      <td>0.997630</td>\n      <td>0.120208</td>\n      <td>0.992749</td>\n      <td>1.000000e+00</td>\n      <td>6.123234e-17</td>\n      <td>1.0</td>\n      <td>6.123234e-17</td>\n    </tr>\n    <tr>\n      <th>2009-01-05</th>\n      <td>0.0</td>\n      <td>0.184805</td>\n      <td>0.049046</td>\n      <td>0.465917</td>\n      <td>0.217391</td>\n      <td>2009</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2</td>\n      <td>...</td>\n      <td>8.660254e-01</td>\n      <td>0.500000</td>\n      <td>0.085965</td>\n      <td>0.996298</td>\n      <td>0.238673</td>\n      <td>0.971100</td>\n      <td>1.000000e+00</td>\n      <td>6.123234e-17</td>\n      <td>1.0</td>\n      <td>6.123234e-17</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-06-26</th>\n      <td>0.0</td>\n      <td>0.591376</td>\n      <td>0.801090</td>\n      <td>0.462974</td>\n      <td>0.304348</td>\n      <td>2020</td>\n      <td>6</td>\n      <td>26</td>\n      <td>178</td>\n      <td>26</td>\n      <td>...</td>\n      <td>-7.431448e-01</td>\n      <td>0.669131</td>\n      <td>0.077386</td>\n      <td>-0.997001</td>\n      <td>0.008610</td>\n      <td>-0.999963</td>\n      <td>1.224647e-16</td>\n      <td>-1.000000e+00</td>\n      <td>-1.0</td>\n      <td>-1.836970e-16</td>\n    </tr>\n    <tr>\n      <th>2020-06-27</th>\n      <td>0.0</td>\n      <td>0.588638</td>\n      <td>0.814714</td>\n      <td>0.408690</td>\n      <td>0.260870</td>\n      <td>2020</td>\n      <td>6</td>\n      <td>27</td>\n      <td>179</td>\n      <td>26</td>\n      <td>...</td>\n      <td>-5.877853e-01</td>\n      <td>0.809017</td>\n      <td>0.060213</td>\n      <td>-0.998186</td>\n      <td>0.008610</td>\n      <td>-0.999963</td>\n      <td>1.224647e-16</td>\n      <td>-1.000000e+00</td>\n      <td>-1.0</td>\n      <td>-1.836970e-16</td>\n    </tr>\n    <tr>\n      <th>2020-06-28</th>\n      <td>0.0</td>\n      <td>0.583162</td>\n      <td>0.833787</td>\n      <td>0.378186</td>\n      <td>0.260870</td>\n      <td>2020</td>\n      <td>6</td>\n      <td>28</td>\n      <td>180</td>\n      <td>26</td>\n      <td>...</td>\n      <td>-4.067366e-01</td>\n      <td>0.913545</td>\n      <td>0.043022</td>\n      <td>-0.999074</td>\n      <td>0.008610</td>\n      <td>-0.999963</td>\n      <td>1.224647e-16</td>\n      <td>-1.000000e+00</td>\n      <td>-1.0</td>\n      <td>-1.836970e-16</td>\n    </tr>\n    <tr>\n      <th>2020-06-29</th>\n      <td>0.0</td>\n      <td>0.583847</td>\n      <td>0.833787</td>\n      <td>0.436952</td>\n      <td>0.260870</td>\n      <td>2020</td>\n      <td>6</td>\n      <td>29</td>\n      <td>181</td>\n      <td>27</td>\n      <td>...</td>\n      <td>-2.079117e-01</td>\n      <td>0.978148</td>\n      <td>0.025818</td>\n      <td>-0.999667</td>\n      <td>-0.111656</td>\n      <td>-0.993747</td>\n      <td>1.224647e-16</td>\n      <td>-1.000000e+00</td>\n      <td>-1.0</td>\n      <td>-1.836970e-16</td>\n    </tr>\n    <tr>\n      <th>2020-06-30</th>\n      <td>0.0</td>\n      <td>0.579055</td>\n      <td>0.844687</td>\n      <td>0.387584</td>\n      <td>0.260870</td>\n      <td>2020</td>\n      <td>6</td>\n      <td>30</td>\n      <td>182</td>\n      <td>27</td>\n      <td>...</td>\n      <td>-1.133108e-15</td>\n      <td>1.000000</td>\n      <td>0.008607</td>\n      <td>-0.999963</td>\n      <td>-0.111656</td>\n      <td>-0.993747</td>\n      <td>1.224647e-16</td>\n      <td>-1.000000e+00</td>\n      <td>-1.0</td>\n      <td>-1.836970e-16</td>\n    </tr>\n  </tbody>\n</table>\n<p>4199 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./files/cycl_data.csv\", index_col=0)\n",
    "df.index = pd.to_datetime(df.index, format='%Y-%m-%d')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "features_cos = ['Rainfall', 'Depth_to_Groundwater', 'Temperature', 'Drainage_Volume', 'River_Hydrometry', 'day_cos',\n",
    "                'month_cos', 'week_of_year_cos', 'quarter_cos', 'season_cos']\n",
    "delete = [feature for feature in df.columns if feature not in features_cos]\n",
    "df_cos = df.drop(delete, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "features_new = ['Depth_to_Groundwater', 'Drainage_Volume', 'River_Hydrometry', 'month_cos', 'week_of_year_cos', 'quarter_cos']\n",
    "delete3 = [feature for feature in df_cos.columns if feature not in features_new]\n",
    "df_new = df_cos.drop(delete3, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "            Depth_to_Groundwater  Drainage_Volume  River_Hydrometry  \\\nDate                                                                  \n2009-01-01              0.175907         0.672018          0.260870   \n2009-01-02              0.177960         0.507291          0.304348   \n2009-01-03              0.180698         0.624189          0.260870   \n2009-01-04              0.182067         0.540839          0.260870   \n2009-01-05              0.184805         0.465917          0.217391   \n...                          ...              ...               ...   \n2020-06-26              0.591376         0.462974          0.304348   \n2020-06-27              0.588638         0.408690          0.260870   \n2020-06-28              0.583162         0.378186          0.260870   \n2020-06-29              0.583847         0.436952          0.260870   \n2020-06-30              0.579055         0.387584          0.260870   \n\n            month_cos  week_of_year_cos   quarter_cos  \nDate                                                   \n2009-01-01   0.866025          0.992749  6.123234e-17  \n2009-01-02   0.866025          0.992749  6.123234e-17  \n2009-01-03   0.866025          0.992749  6.123234e-17  \n2009-01-04   0.866025          0.992749  6.123234e-17  \n2009-01-05   0.866025          0.971100  6.123234e-17  \n...               ...               ...           ...  \n2020-06-26  -1.000000         -0.999963 -1.000000e+00  \n2020-06-27  -1.000000         -0.999963 -1.000000e+00  \n2020-06-28  -1.000000         -0.999963 -1.000000e+00  \n2020-06-29  -1.000000         -0.993747 -1.000000e+00  \n2020-06-30  -1.000000         -0.993747 -1.000000e+00  \n\n[4199 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Depth_to_Groundwater</th>\n      <th>Drainage_Volume</th>\n      <th>River_Hydrometry</th>\n      <th>month_cos</th>\n      <th>week_of_year_cos</th>\n      <th>quarter_cos</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2009-01-01</th>\n      <td>0.175907</td>\n      <td>0.672018</td>\n      <td>0.260870</td>\n      <td>0.866025</td>\n      <td>0.992749</td>\n      <td>6.123234e-17</td>\n    </tr>\n    <tr>\n      <th>2009-01-02</th>\n      <td>0.177960</td>\n      <td>0.507291</td>\n      <td>0.304348</td>\n      <td>0.866025</td>\n      <td>0.992749</td>\n      <td>6.123234e-17</td>\n    </tr>\n    <tr>\n      <th>2009-01-03</th>\n      <td>0.180698</td>\n      <td>0.624189</td>\n      <td>0.260870</td>\n      <td>0.866025</td>\n      <td>0.992749</td>\n      <td>6.123234e-17</td>\n    </tr>\n    <tr>\n      <th>2009-01-04</th>\n      <td>0.182067</td>\n      <td>0.540839</td>\n      <td>0.260870</td>\n      <td>0.866025</td>\n      <td>0.992749</td>\n      <td>6.123234e-17</td>\n    </tr>\n    <tr>\n      <th>2009-01-05</th>\n      <td>0.184805</td>\n      <td>0.465917</td>\n      <td>0.217391</td>\n      <td>0.866025</td>\n      <td>0.971100</td>\n      <td>6.123234e-17</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-06-26</th>\n      <td>0.591376</td>\n      <td>0.462974</td>\n      <td>0.304348</td>\n      <td>-1.000000</td>\n      <td>-0.999963</td>\n      <td>-1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>2020-06-27</th>\n      <td>0.588638</td>\n      <td>0.408690</td>\n      <td>0.260870</td>\n      <td>-1.000000</td>\n      <td>-0.999963</td>\n      <td>-1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>2020-06-28</th>\n      <td>0.583162</td>\n      <td>0.378186</td>\n      <td>0.260870</td>\n      <td>-1.000000</td>\n      <td>-0.999963</td>\n      <td>-1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>2020-06-29</th>\n      <td>0.583847</td>\n      <td>0.436952</td>\n      <td>0.260870</td>\n      <td>-1.000000</td>\n      <td>-0.993747</td>\n      <td>-1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>2020-06-30</th>\n      <td>0.579055</td>\n      <td>0.387584</td>\n      <td>0.260870</td>\n      <td>-1.000000</td>\n      <td>-0.993747</td>\n      <td>-1.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n<p>4199 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_new\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "N_FEATURES  = 6  # multivariate\n",
    "N_STEPS_IN  = 5 # static window\n",
    "N_STEPS_OUT = 1  # single-step\n",
    "TRAIN_SIZE = int((len(df.index)-N_STEPS_IN) * 0.5)\n",
    "VAL_SIZE = int((len(df.index)-N_STEPS_IN) * 0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def df_to_X_y(df):\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np) - N_STEPS_IN):\n",
    "        row = [r for r in df_as_np[i:i + N_STEPS_IN]]\n",
    "        X.append(row)\n",
    "        label = df_as_np[i + N_STEPS_IN][0]\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def get_sets(df):\n",
    "    X1, y1 = df_to_X_y(df)\n",
    "    X_train1, y_train1 = X1[:TRAIN_SIZE], y1[:TRAIN_SIZE]\n",
    "    X_val1, y_val1 = X1[TRAIN_SIZE:TRAIN_SIZE + VAL_SIZE], y1[TRAIN_SIZE:TRAIN_SIZE + VAL_SIZE]\n",
    "    X_test1, y_test1 = X1[TRAIN_SIZE + VAL_SIZE:], y1[TRAIN_SIZE + VAL_SIZE:]\n",
    "    return X1, y1, X_train1, y_train1, X_val1, y_val1, X_test1, y_test1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([64, 96, 128]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam' ,'nadam']))\n",
    "\n",
    "METRIC_RMSE = 'RootMeanSquaredError'\n",
    "\n",
    "logdir = 'logs/hparam_tuning_multi'\n",
    "with tf.summary.create_file_writer(logdir).as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "        metrics=[hp.Metric(METRIC_RMSE, display_name='RMSE')]\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def init_model(hparams):\n",
    "    # Use initializers to initialize model parameters with the same values\n",
    "    INITIALIZER_GLOROT_UNIFORM = tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    "    INITIALIZER_ORTHOGONAL = tf.keras.initializers.Orthogonal(gain=1.0, seed=SEED)\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer((N_STEPS_IN, N_FEATURES)))\n",
    "    model.add(LSTM(units=hparams[HP_NUM_UNITS],\n",
    "                   kernel_initializer=INITIALIZER_GLOROT_UNIFORM,\n",
    "                   recurrent_initializer=INITIALIZER_ORTHOGONAL))\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    model.add(Dense(units=8, activation='relu', kernel_initializer=INITIALIZER_GLOROT_UNIFORM))\n",
    "    model.add(Dense(units=N_STEPS_OUT,\n",
    "                    kernel_initializer=INITIALIZER_GLOROT_UNIFORM,\n",
    "                    activation='linear'))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def train_model(df, hparams):\n",
    "    X1, y1, X_train1, y_train1, X_val1, y_val1, X_test1, y_test1 = get_sets(df)\n",
    "    model = init_model(hparams)\n",
    "    model.compile(loss=MeanSquaredError(), optimizer=hparams[HP_OPTIMIZER], metrics=[RootMeanSquaredError()])\n",
    "    model.fit(X_train1, y_train1, validation_data=(X_val1, y_val1), epochs=10, callbacks=[\n",
    "        tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
    "        hp.KerasCallback(logdir, hparams),  # log hparams\n",
    "    ])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def train_test_model(df, hparams):\n",
    "    X1, y1, X_train1, y_train1, X_val1, y_val1, X_test1, y_test1 = get_sets(df)\n",
    "    model = train_model(df, hparams)\n",
    "    _, rmse = model.evaluate(X_test1, y_test1)\n",
    "    return  rmse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        rmse = train_test_model(df, hparams)\n",
    "        tf.summary.scalar(METRIC_RMSE, rmse, step=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 4s 12ms/step - loss: 0.0495 - root_mean_squared_error: 0.2225 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.0011 - root_mean_squared_error: 0.0334 - val_loss: 1.8315e-04 - val_root_mean_squared_error: 0.0135\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 2.7398e-04 - root_mean_squared_error: 0.0166 - val_loss: 1.9406e-04 - val_root_mean_squared_error: 0.0139\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1.8436e-04 - root_mean_squared_error: 0.0136 - val_loss: 9.2364e-05 - val_root_mean_squared_error: 0.0096\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1.2077e-04 - root_mean_squared_error: 0.0110 - val_loss: 1.4281e-04 - val_root_mean_squared_error: 0.0120\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 9.1207e-05 - root_mean_squared_error: 0.0096 - val_loss: 7.1199e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 7.1722e-05 - root_mean_squared_error: 0.0085 - val_loss: 5.0890e-05 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.6787e-05 - root_mean_squared_error: 0.0082 - val_loss: 6.5259e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 6.4583e-05 - root_mean_squared_error: 0.0080 - val_loss: 9.9984e-05 - val_root_mean_squared_error: 0.0100\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.9274e-05 - root_mean_squared_error: 0.0077 - val_loss: 6.7181e-05 - val_root_mean_squared_error: 0.0082\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.0577e-05 - root_mean_squared_error: 0.0084\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'nadam'}\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 5s 17ms/step - loss: 0.0547 - root_mean_squared_error: 0.2339 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.5997e-04 - root_mean_squared_error: 0.0257 - val_loss: 2.2596e-04 - val_root_mean_squared_error: 0.0150\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 1.7998e-04 - root_mean_squared_error: 0.0134 - val_loss: 1.3136e-04 - val_root_mean_squared_error: 0.0115\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.1964e-04 - root_mean_squared_error: 0.0109 - val_loss: 7.7845e-05 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 9.4636e-05 - root_mean_squared_error: 0.0097 - val_loss: 1.2188e-04 - val_root_mean_squared_error: 0.0110\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 8.3797e-05 - root_mean_squared_error: 0.0092 - val_loss: 1.0748e-04 - val_root_mean_squared_error: 0.0104\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 7.5995e-05 - root_mean_squared_error: 0.0087 - val_loss: 6.8463e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.9190e-05 - root_mean_squared_error: 0.0083 - val_loss: 6.1344e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.5849e-05 - root_mean_squared_error: 0.0081 - val_loss: 9.4602e-05 - val_root_mean_squared_error: 0.0097\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 6.1933e-05 - root_mean_squared_error: 0.0079 - val_loss: 8.6241e-05 - val_root_mean_squared_error: 0.0093\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 8.5854e-05 - root_mean_squared_error: 0.0093\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 64, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 4s 11ms/step - loss: 0.0495 - root_mean_squared_error: 0.2225 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.0011 - root_mean_squared_error: 0.0334 - val_loss: 1.8315e-04 - val_root_mean_squared_error: 0.0135\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 2.7398e-04 - root_mean_squared_error: 0.0166 - val_loss: 1.9406e-04 - val_root_mean_squared_error: 0.0139\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1.8436e-04 - root_mean_squared_error: 0.0136 - val_loss: 9.2364e-05 - val_root_mean_squared_error: 0.0096\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 1.2077e-04 - root_mean_squared_error: 0.0110 - val_loss: 1.4281e-04 - val_root_mean_squared_error: 0.0120\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 9.1207e-05 - root_mean_squared_error: 0.0096 - val_loss: 7.1199e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 7.1722e-05 - root_mean_squared_error: 0.0085 - val_loss: 5.0890e-05 - val_root_mean_squared_error: 0.0071\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 6.6787e-05 - root_mean_squared_error: 0.0082 - val_loss: 6.5259e-05 - val_root_mean_squared_error: 0.0081\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 6.4583e-05 - root_mean_squared_error: 0.0080 - val_loss: 9.9984e-05 - val_root_mean_squared_error: 0.0100\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.9274e-05 - root_mean_squared_error: 0.0077 - val_loss: 6.7181e-05 - val_root_mean_squared_error: 0.0082\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.0577e-05 - root_mean_squared_error: 0.0084\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 64, 'dropout': 0.2, 'optimizer': 'nadam'}\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 4s 14ms/step - loss: 0.0547 - root_mean_squared_error: 0.2339 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0343\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 6.5997e-04 - root_mean_squared_error: 0.0257 - val_loss: 2.2596e-04 - val_root_mean_squared_error: 0.0150\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1.7998e-04 - root_mean_squared_error: 0.0134 - val_loss: 1.3136e-04 - val_root_mean_squared_error: 0.0115\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1.1964e-04 - root_mean_squared_error: 0.0109 - val_loss: 7.7845e-05 - val_root_mean_squared_error: 0.0088\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 9.4636e-05 - root_mean_squared_error: 0.0097 - val_loss: 1.2188e-04 - val_root_mean_squared_error: 0.0110\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 8.3797e-05 - root_mean_squared_error: 0.0092 - val_loss: 1.0748e-04 - val_root_mean_squared_error: 0.0104\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 7.5995e-05 - root_mean_squared_error: 0.0087 - val_loss: 6.8463e-05 - val_root_mean_squared_error: 0.0083\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.9190e-05 - root_mean_squared_error: 0.0083 - val_loss: 6.1344e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 6.5849e-05 - root_mean_squared_error: 0.0081 - val_loss: 9.4602e-05 - val_root_mean_squared_error: 0.0097\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.1933e-05 - root_mean_squared_error: 0.0079 - val_loss: 8.6241e-05 - val_root_mean_squared_error: 0.0093\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.5854e-05 - root_mean_squared_error: 0.0093\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 96, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 3s 12ms/step - loss: 0.0392 - root_mean_squared_error: 0.1979 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5.6817e-04 - root_mean_squared_error: 0.0238 - val_loss: 3.2269e-04 - val_root_mean_squared_error: 0.0180\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1.6762e-04 - root_mean_squared_error: 0.0129 - val_loss: 2.0013e-04 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1.1842e-04 - root_mean_squared_error: 0.0109 - val_loss: 1.4430e-04 - val_root_mean_squared_error: 0.0120\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 8.6868e-05 - root_mean_squared_error: 0.0093 - val_loss: 1.6641e-04 - val_root_mean_squared_error: 0.0129\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 7.4970e-05 - root_mean_squared_error: 0.0087 - val_loss: 1.2863e-04 - val_root_mean_squared_error: 0.0113\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.6717e-05 - root_mean_squared_error: 0.0082 - val_loss: 8.6622e-05 - val_root_mean_squared_error: 0.0093\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.3187e-05 - root_mean_squared_error: 0.0079 - val_loss: 8.1245e-05 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 8ms/step - loss: 5.7857e-05 - root_mean_squared_error: 0.0076 - val_loss: 1.0344e-04 - val_root_mean_squared_error: 0.0102\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 5.7324e-05 - root_mean_squared_error: 0.0076 - val_loss: 9.7614e-05 - val_root_mean_squared_error: 0.0099\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 8.2747e-05 - root_mean_squared_error: 0.0091\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 96, 'dropout': 0.1, 'optimizer': 'nadam'}\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 5s 16ms/step - loss: 0.0451 - root_mean_squared_error: 0.2125 - val_loss: 7.8560e-04 - val_root_mean_squared_error: 0.0280\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4.6617e-04 - root_mean_squared_error: 0.0216 - val_loss: 2.2284e-04 - val_root_mean_squared_error: 0.0149\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1.7522e-04 - root_mean_squared_error: 0.0132 - val_loss: 1.5927e-04 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1.1882e-04 - root_mean_squared_error: 0.0109 - val_loss: 1.1852e-04 - val_root_mean_squared_error: 0.0109\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 8.9809e-05 - root_mean_squared_error: 0.0095 - val_loss: 1.1210e-04 - val_root_mean_squared_error: 0.0106\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 7.5635e-05 - root_mean_squared_error: 0.0087 - val_loss: 1.4802e-04 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 6.6538e-05 - root_mean_squared_error: 0.0082 - val_loss: 6.7310e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 6.1360e-05 - root_mean_squared_error: 0.0078 - val_loss: 6.6453e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.6918e-05 - root_mean_squared_error: 0.0075 - val_loss: 1.0359e-04 - val_root_mean_squared_error: 0.0102\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.4362e-05 - root_mean_squared_error: 0.0074 - val_loss: 1.0890e-04 - val_root_mean_squared_error: 0.0104\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.6323e-05 - root_mean_squared_error: 0.0087\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 96, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 4s 16ms/step - loss: 0.0392 - root_mean_squared_error: 0.1979 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0363\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.6817e-04 - root_mean_squared_error: 0.0238 - val_loss: 3.2269e-04 - val_root_mean_squared_error: 0.0180\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 1.6762e-04 - root_mean_squared_error: 0.0129 - val_loss: 2.0013e-04 - val_root_mean_squared_error: 0.0141\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 1.1842e-04 - root_mean_squared_error: 0.0109 - val_loss: 1.4430e-04 - val_root_mean_squared_error: 0.0120\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 8.6868e-05 - root_mean_squared_error: 0.0093 - val_loss: 1.6641e-04 - val_root_mean_squared_error: 0.0129\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 7.4970e-05 - root_mean_squared_error: 0.0087 - val_loss: 1.2863e-04 - val_root_mean_squared_error: 0.0113\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 6.6717e-05 - root_mean_squared_error: 0.0082 - val_loss: 8.6622e-05 - val_root_mean_squared_error: 0.0093\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 6.3187e-05 - root_mean_squared_error: 0.0079 - val_loss: 8.1245e-05 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.7857e-05 - root_mean_squared_error: 0.0076 - val_loss: 1.0344e-04 - val_root_mean_squared_error: 0.0102\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.7324e-05 - root_mean_squared_error: 0.0076 - val_loss: 9.7614e-05 - val_root_mean_squared_error: 0.0099\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 8.2747e-05 - root_mean_squared_error: 0.0091\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 96, 'dropout': 0.2, 'optimizer': 'nadam'}\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 4s 12ms/step - loss: 0.0451 - root_mean_squared_error: 0.2125 - val_loss: 7.8560e-04 - val_root_mean_squared_error: 0.0280\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 4.6617e-04 - root_mean_squared_error: 0.0216 - val_loss: 2.2284e-04 - val_root_mean_squared_error: 0.0149\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1.7522e-04 - root_mean_squared_error: 0.0132 - val_loss: 1.5927e-04 - val_root_mean_squared_error: 0.0126\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1.1882e-04 - root_mean_squared_error: 0.0109 - val_loss: 1.1852e-04 - val_root_mean_squared_error: 0.0109\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 8.9809e-05 - root_mean_squared_error: 0.0095 - val_loss: 1.1210e-04 - val_root_mean_squared_error: 0.0106\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 7.5635e-05 - root_mean_squared_error: 0.0087 - val_loss: 1.4802e-04 - val_root_mean_squared_error: 0.0122\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.6538e-05 - root_mean_squared_error: 0.0082 - val_loss: 6.7310e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.1360e-05 - root_mean_squared_error: 0.0078 - val_loss: 6.6453e-05 - val_root_mean_squared_error: 0.0082\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.6918e-05 - root_mean_squared_error: 0.0075 - val_loss: 1.0359e-04 - val_root_mean_squared_error: 0.0102\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.4362e-05 - root_mean_squared_error: 0.0074 - val_loss: 1.0890e-04 - val_root_mean_squared_error: 0.0104\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.6323e-05 - root_mean_squared_error: 0.0087\n",
      "--- Starting trial: run-8\n",
      "{'num_units': 128, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 4s 16ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 6.8762e-04 - val_root_mean_squared_error: 0.0262\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 2.7765e-04 - root_mean_squared_error: 0.0167 - val_loss: 2.1474e-04 - val_root_mean_squared_error: 0.0147\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.4886e-04 - root_mean_squared_error: 0.0122 - val_loss: 1.0986e-04 - val_root_mean_squared_error: 0.0105\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.2830e-04 - root_mean_squared_error: 0.0113 - val_loss: 9.6666e-05 - val_root_mean_squared_error: 0.0098\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 1.0260e-04 - root_mean_squared_error: 0.0101 - val_loss: 6.4556e-05 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 9.8740e-05 - root_mean_squared_error: 0.0099 - val_loss: 9.5319e-05 - val_root_mean_squared_error: 0.0098\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 8.9539e-05 - root_mean_squared_error: 0.0095 - val_loss: 7.1036e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 7.5623e-05 - root_mean_squared_error: 0.0087 - val_loss: 5.5029e-05 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.3170e-05 - root_mean_squared_error: 0.0079 - val_loss: 7.1804e-05 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.2363e-05 - root_mean_squared_error: 0.0079 - val_loss: 6.3334e-05 - val_root_mean_squared_error: 0.0080\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.2918e-05 - root_mean_squared_error: 0.0085\n",
      "--- Starting trial: run-9\n",
      "{'num_units': 128, 'dropout': 0.1, 'optimizer': 'nadam'}\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 4s 19ms/step - loss: 0.0266 - root_mean_squared_error: 0.1632 - val_loss: 3.0439e-04 - val_root_mean_squared_error: 0.0174\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 2.2767e-04 - root_mean_squared_error: 0.0151 - val_loss: 1.6105e-04 - val_root_mean_squared_error: 0.0127\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.3589e-04 - root_mean_squared_error: 0.0117 - val_loss: 1.0556e-04 - val_root_mean_squared_error: 0.0103\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 1.0544e-04 - root_mean_squared_error: 0.0103 - val_loss: 6.1556e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 7.9868e-05 - root_mean_squared_error: 0.0089 - val_loss: 8.1097e-05 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 6.8721e-05 - root_mean_squared_error: 0.0083 - val_loss: 8.9064e-05 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 6.2321e-05 - root_mean_squared_error: 0.0079 - val_loss: 7.5052e-05 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 5.5314e-05 - root_mean_squared_error: 0.0074 - val_loss: 4.6805e-05 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.3958e-05 - root_mean_squared_error: 0.0073 - val_loss: 3.9787e-05 - val_root_mean_squared_error: 0.0063\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 5.4046e-05 - root_mean_squared_error: 0.0074 - val_loss: 3.9800e-05 - val_root_mean_squared_error: 0.0063\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.0997e-05 - root_mean_squared_error: 0.0084\n",
      "--- Starting trial: run-10\n",
      "{'num_units': 128, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 3s 13ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - val_loss: 6.8762e-04 - val_root_mean_squared_error: 0.0262\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 2.7765e-04 - root_mean_squared_error: 0.0167 - val_loss: 2.1474e-04 - val_root_mean_squared_error: 0.0147\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 8ms/step - loss: 1.4886e-04 - root_mean_squared_error: 0.0122 - val_loss: 1.0986e-04 - val_root_mean_squared_error: 0.0105\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.2830e-04 - root_mean_squared_error: 0.0113 - val_loss: 9.6666e-05 - val_root_mean_squared_error: 0.0098\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.0260e-04 - root_mean_squared_error: 0.0101 - val_loss: 6.4556e-05 - val_root_mean_squared_error: 0.0080\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 9.8740e-05 - root_mean_squared_error: 0.0099 - val_loss: 9.5319e-05 - val_root_mean_squared_error: 0.0098\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 8.9539e-05 - root_mean_squared_error: 0.0095 - val_loss: 7.1036e-05 - val_root_mean_squared_error: 0.0084\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 7.5623e-05 - root_mean_squared_error: 0.0087 - val_loss: 5.5029e-05 - val_root_mean_squared_error: 0.0074\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.3170e-05 - root_mean_squared_error: 0.0079 - val_loss: 7.1804e-05 - val_root_mean_squared_error: 0.0085\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 6.2363e-05 - root_mean_squared_error: 0.0079 - val_loss: 6.3334e-05 - val_root_mean_squared_error: 0.0080\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.2918e-05 - root_mean_squared_error: 0.0085\n",
      "--- Starting trial: run-11\n",
      "{'num_units': 128, 'dropout': 0.2, 'optimizer': 'nadam'}\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 5s 16ms/step - loss: 0.0266 - root_mean_squared_error: 0.1632 - val_loss: 3.0439e-04 - val_root_mean_squared_error: 0.0174\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 2.2767e-04 - root_mean_squared_error: 0.0151 - val_loss: 1.6105e-04 - val_root_mean_squared_error: 0.0127\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 1.3589e-04 - root_mean_squared_error: 0.0117 - val_loss: 1.0556e-04 - val_root_mean_squared_error: 0.0103\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 1.0544e-04 - root_mean_squared_error: 0.0103 - val_loss: 6.1556e-05 - val_root_mean_squared_error: 0.0078\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 7.9868e-05 - root_mean_squared_error: 0.0089 - val_loss: 8.1097e-05 - val_root_mean_squared_error: 0.0090\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.8721e-05 - root_mean_squared_error: 0.0083 - val_loss: 8.9064e-05 - val_root_mean_squared_error: 0.0094\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.2321e-05 - root_mean_squared_error: 0.0079 - val_loss: 7.5052e-05 - val_root_mean_squared_error: 0.0087\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 5.5314e-05 - root_mean_squared_error: 0.0074 - val_loss: 4.6805e-05 - val_root_mean_squared_error: 0.0068\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 5.3958e-05 - root_mean_squared_error: 0.0073 - val_loss: 3.9787e-05 - val_root_mean_squared_error: 0.0063\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5.4046e-05 - root_mean_squared_error: 0.0074 - val_loss: 3.9800e-05 - val_root_mean_squared_error: 0.0063\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 7.0997e-05 - root_mean_squared_error: 0.0084\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_OPTIMIZER: optimizer,\n",
    "            }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('logs/hparam_tuning/multi2/' + run_name, hparams)\n",
    "            session_num += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- run-0\n",
      "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "--- run-1\n",
      "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'nadam'}\n",
      "--- run-2\n",
      "{'num_units': 64, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "--- run-3\n",
      "{'num_units': 64, 'dropout': 0.2, 'optimizer': 'nadam'}\n",
      "--- run-4\n",
      "{'num_units': 96, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "--- run-5\n",
      "{'num_units': 96, 'dropout': 0.1, 'optimizer': 'nadam'}\n",
      "--- run-6\n",
      "{'num_units': 96, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "--- run-7\n",
      "{'num_units': 96, 'dropout': 0.2, 'optimizer': 'nadam'}\n",
      "--- run-8\n",
      "{'num_units': 128, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "--- run-9\n",
      "{'num_units': 128, 'dropout': 0.1, 'optimizer': 'nadam'}\n",
      "--- run-10\n",
      "{'num_units': 128, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "--- run-11\n",
      "{'num_units': 128, 'dropout': 0.2, 'optimizer': 'nadam'}\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_OPTIMIZER: optimizer,\n",
    "            }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            #run('logs/hparam_tuning/multi2/' + run_name, hparams)\n",
    "            session_num += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "{'num_units': 96, 'dropout': 0.1, 'optimizer': 'adam'}\n",
    "\n",
    "{'num_units': 32, 'num_units_sec': 128, 'dropout': 0.2, 'optimizer': 'nadam'} 0.0082\n",
    "{'num_units': 64, 'num_units_sec': 64, 'dropout': 0.1, 'optimizer': 'adam'} 0.0089\n",
    "\n",
    "\n",
    "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'nadam'} 0.0933\n",
    "{'num_units': 64, 'dropout': 0.1, 'optimizer': 'nadam'} 0.08706\n",
    "{'num_units': 64, 'dropout': 0.2, 'optimizer': 'adam'} 0.0856"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-271ef9ddf586b12a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-271ef9ddf586b12a\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning_multi/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import winsound\n",
    "winsound.Beep(2500,1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}